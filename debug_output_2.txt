
Initializing RAG Engine...

Querying: 'What is my Date of Birth according to my health records?'

--- Direct Retrieval Check ---
Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 7219.11it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 2513.06it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2908.67it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2647.08it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 3408.16it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 3238.01it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 3847.99it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 3133.00it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 2907.46it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 2802.93it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 2225.88it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 2063.11it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 2201.07it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 1948.64it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 2099.78it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 2064.89it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 2239.88it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 2184.79it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 2207.53it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 2130.49it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 2197.54it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 2097.06it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 2181.50it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 2158.30it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2270.12it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2207.53it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2224.50it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2164.08it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 2257.02it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 2234.34it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 2153.96it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 2134.30it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 2219.76it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 2174.01it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 2165.30it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 2147.25it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 2202.59it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 2141.50it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 2155.24it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 2131.25it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 2148.04it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 2129.71it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 2185.78it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 2170.96it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2190.63it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2178.56it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2251.77it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2236.47it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2236.58it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2214.62it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2236.64it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2201.47it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2228.55it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2178.06it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2194.29it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2182.58it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2234.29it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2225.01it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2280.01it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2249.04it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2250.63it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2233.73it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2278.27it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2221.89it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2261.19it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2233.24it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2242.63it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2231.12it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2269.26it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2235.74it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2226.87it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2207.79it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2230.37it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2214.49it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2188.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2177.49it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2213.38it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2194.59it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2216.60it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2195.91it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2190.10it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2169.62it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2169.57it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2141.90it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2170.47it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2161.55it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2177.09it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2157.66it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2184.56it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2176.97it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2211.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2204.58it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2239.63it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2233.89it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2270.72it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2264.97it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2301.18it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2295.55it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2331.41it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2325.00it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2358.12it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2350.71it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2384.93it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2378.55it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2413.19it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2407.75it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2442.49it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2436.63it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2466.68it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2459.87it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2493.14it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2487.28it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2513.14it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2506.95it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2540.33it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2534.03it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2565.78it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2559.72it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2592.22it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2586.50it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2618.27it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2612.26it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2643.05it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2636.64it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2667.84it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2661.33it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2691.30it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2684.44it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2713.44it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2706.32it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2734.39it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2726.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2748.78it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2740.15it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2764.68it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2757.20it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2782.81it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2775.18it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2801.81it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2794.82it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2820.22it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2813.77it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2838.06it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2831.39it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2858.22it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2851.51it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2877.55it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2870.55it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2895.85it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2888.08it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2912.76it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2905.12it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2926.89it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2921.46it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2950.91it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2946.13it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2974.66it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2970.52it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2998.15it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2992.19it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 3021.21it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 3016.68it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3045.92it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3041.93it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3071.58it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3067.66it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3094.99it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3091.38it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3121.58it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3117.90it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3147.97it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3144.29it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3170.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3165.57it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3194.58it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3190.80it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3219.71it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3215.94it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3245.28it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3241.60it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3270.23it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3266.51it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3295.49it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3291.87it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3320.74it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3316.95it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3345.76it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3342.02it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3370.57it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3366.81it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3394.94it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3390.16it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3417.42it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3413.55it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3442.27it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3438.64it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3464.86it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3461.05it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3488.94it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3485.18it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3512.61it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3508.92it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3536.72it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3532.72it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3560.41it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3556.57it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3543.97it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
Found 5 results.

Result 1 (Source: health_folder):
Content: itoring of kidney function due to hereditary risk.
This document summarizes your health trends based on medical records from 2021û2025 and your
recent lifestyle updates....

Result 2 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 3 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 4 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 5 (Source: finance_folder):
Content: ns made so you may file them
with your tax return. If your name and SSN are correct but
arenÆt the same as shown on your social security card, you
should ask for a new card that displays your correct name
at any SSA office or by calling 800-772-1213. You may also
visit the SSA website at www.SSA.gov...

--- Full Generation Check ---

Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/105 [00:00<00:00, 30174.85it/s, Materializing param=bert.embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/105 [00:00<00:00, 9425.40it/s, Materializing param=bert.embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/105 [00:00<00:00, 5426.01it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/105 [00:00<00:00, 3269.14it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 3713.96it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 3422.06it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 3292.23it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 2831.60it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/105 [00:00<00:00, 2913.52it/s, Materializing param=bert.embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/105 [00:00<00:00, 2791.74it/s, Materializing param=bert.embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 3045.24it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 2797.45it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 2920.53it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 2669.35it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/105 [00:00<00:00, 2633.17it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/105 [00:00<00:00, 2550.89it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2722.20it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2658.92it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2785.62it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2587.48it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2735.36it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2578.08it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2676.50it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2578.20it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2655.27it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2615.28it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2663.05it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]  
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2531.05it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2582.28it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2540.87it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2613.38it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]    
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2586.28it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2521.51it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2465.36it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2465.22it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2433.75it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2433.26it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2409.57it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2385.77it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2362.46it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2343.56it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2324.94it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2390.04it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2308.25it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2329.89it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2282.05it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2306.46it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2290.46it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2330.89it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2286.67it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2256.08it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2241.47it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2246.59it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2230.09it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2282.70it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2269.12it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2273.34it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2261.04it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2302.16it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2259.29it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2268.34it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2256.65it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2304.56it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]    
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2278.82it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2330.68it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2322.43it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2347.08it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2336.39it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2382.47it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2372.96it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2398.12it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]      
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2356.87it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2351.03it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2312.81it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2330.34it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2321.07it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2285.76it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2277.26it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2317.10it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]      
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2282.27it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2304.35it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2295.33it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2326.66it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]      
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2318.15it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2352.78it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2345.59it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2350.59it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2327.70it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2346.07it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2333.19it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2332.03it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]  
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2303.79it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2319.37it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2301.55it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2315.16it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]    
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2303.14it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2334.43it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2328.19it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2365.44it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2360.33it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2397.82it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2392.75it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2430.32it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]      
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2425.48it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2462.56it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2457.55it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2493.56it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2487.75it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2521.97it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2515.56it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2550.37it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]      
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2545.28it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2579.36it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2573.61it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2603.62it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]      
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2577.09it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2519.08it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2475.63it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2503.81it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2498.49it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2529.64it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2524.17it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2529.42it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]  
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2516.03it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2539.56it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2532.50it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2556.04it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]    
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2546.68it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2572.03it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2566.12it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2596.31it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2591.89it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2621.51it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2616.56it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2646.45it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]      
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2641.69it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2672.20it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2667.71it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2696.66it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2691.91it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2706.42it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2698.52it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2716.18it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]      
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2704.40it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2721.95it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2710.19it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2726.47it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]      
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2719.47it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2743.29it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2735.75it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2759.43it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2752.76it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2778.23it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2772.96it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2799.27it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]  
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2793.93it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2819.69it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2813.87it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2838.69it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]    
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2832.31it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2851.78it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2843.67it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2861.15it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2854.52it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2876.44it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2871.39it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2896.14it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]      
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2890.87it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2914.23it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2909.34it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2934.73it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2929.77it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2953.62it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2948.58it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 2973.20it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]      
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 2968.13it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 2993.07it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 2988.71it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 3014.30it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]      
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 3010.17it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 3035.07it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 3030.83it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 3056.15it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 3052.00it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 3077.14it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 3072.92it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3096.91it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]  
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3092.59it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3117.15it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3112.28it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3135.17it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]    
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3130.54it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3154.69it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3150.49it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3174.68it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3170.40it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3194.22it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3189.95it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3213.71it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]     
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3209.28it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3233.13it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3228.77it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3252.76it/s, Materializing param=bert.pooler.dense.bias]                  
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3248.58it/s, Materializing param=bert.pooler.dense.bias]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3272.16it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3268.00it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3292.58it/s, Materializing param=classifier.bias]         
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3288.63it/s, Materializing param=classifier.bias]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3313.16it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3308.71it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3296.42it/s, Materializing param=classifier.weight]
BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2
Key                          | Status     |  | 
-----------------------------+------------+--+-
bert.embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
Traceback (most recent call last):
  File "C:\Users\jared\Vibe Coding (root)\Projects\jrocks-personal-ai\debug_rag.py", line 46, in <module>
    asyncio.run(test_retrieval())
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.3312.0_x64__qbz5n2kfra8p0\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.3312.0_x64__qbz5n2kfra8p0\Lib\asyncio\runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.3312.0_x64__qbz5n2kfra8p0\Lib\asyncio\base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "C:\Users\jared\Vibe Coding (root)\Projects\jrocks-personal-ai\debug_rag.py", line 41, in test_retrieval
    response = await rag.generate_response(query, system_prompt="You are Jared.")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: object str can't be used in 'await' expression
