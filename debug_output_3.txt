Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
Initializing RAG Engine...

Querying: 'What is my Date of Birth according to my health records?'

--- Direct Retrieval Check ---

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 12748.64it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 6967.28it/s, Materializing param=embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/103 [00:00<00:00, 6181.73it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 5207.08it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 4786.20it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 4415.06it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 4420.87it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 4203.76it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 4359.08it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 4129.88it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 4226.71it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 4080.06it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 4205.72it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 4055.83it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 4406.94it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 3954.09it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 3831.97it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 3537.84it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 3702.27it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 3632.38it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 3670.43it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 3559.71it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 3086.32it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 2873.30it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2919.73it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 2870.84it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2839.75it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 2710.37it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 2224.70it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 2196.28it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 2283.00it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 2233.83it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 2331.24it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 2291.23it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 2218.56it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 2178.80it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 2254.49it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 2236.59it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 2298.25it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 2279.82it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 2358.56it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 2298.25it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 2343.42it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 2314.62it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2353.59it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 2339.10it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2335.58it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 2307.63it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2311.98it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 2293.57it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2327.68it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2291.34it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2330.12it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2309.97it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2366.56it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2337.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2397.97it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2368.09it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2282.03it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2268.17it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2320.44it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2265.30it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2311.99it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2293.30it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2334.10it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2324.38it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2350.25it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2340.15it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2387.39it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2380.19it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2428.94it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2403.08it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2443.39it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 2434.23it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2433.86it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 2424.60it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2436.37it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 2416.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2457.08it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 2432.19it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2443.75it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 2429.66it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2418.86it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 2402.83it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2399.26it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 2376.63it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2368.29it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 2358.40it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2392.34it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 2346.07it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2367.08it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 2340.12it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2363.04it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 2355.03it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2391.05it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 2384.60it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2407.84it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 2400.69it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2430.02it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 2411.52it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2439.38it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 2431.78it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2457.59it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2448.71it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2453.35it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2439.41it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2465.65it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2448.06it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2478.48it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2473.32it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2509.73it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2505.75it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2542.95it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2539.14it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2576.57it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2572.92it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2609.80it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2605.95it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2642.83it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2639.14it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2675.78it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2672.01it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2706.68it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2702.60it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2738.70it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2734.85it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2762.88it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2755.93it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2788.79it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2784.04it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2818.35it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2814.00it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2846.51it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2841.21it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2875.94it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2872.06it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2906.63it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2902.75it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2937.63it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2933.75it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2967.45it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2963.52it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2994.80it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2990.86it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 3023.74it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 3019.72it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 3053.40it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 3049.35it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 3082.51it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 3078.73it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 3111.17it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 3105.38it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 3133.75it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 3127.05it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 3155.47it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 3149.39it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 3178.05it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 3171.85it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 3200.05it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 3195.23it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 3225.74it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 3213.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3238.97it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 3218.09it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3238.45it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 3234.03it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3263.20it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 3256.99it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3284.83it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 3278.97it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3306.63it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 3300.43it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3329.39it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 3325.29it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3355.93it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 3351.79it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3382.29it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 3378.40it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3409.39it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 3405.54it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3436.07it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 3431.93it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3461.89it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 3457.89it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3488.03it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 3484.05it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3513.88it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 3509.82it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3537.17it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 3532.09it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3553.15it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 3546.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3569.65it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 3564.43it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3592.93it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 3588.76it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3615.87it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 3611.41it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3638.90it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 3634.33it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3661.25it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 3656.76it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3684.82it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 3679.85it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3705.09it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3699.50it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 3681.19it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
Found 5 results.

Result 1 (Source: health_folder):
Content: itoring of kidney function due to hereditary risk.
This document summarizes your health trends based on medical records from 2021û2025 and your
recent lifestyle updates....

Result 2 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 3 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 4 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 5 (Source: finance_folder):
Content: ns made so you may file them
with your tax return. If your name and SSN are correct but
arenÆt the same as shown on your social security card, you
should ask for a new card that displays your correct name
at any SSA office or by calling 800-772-1213. You may also
visit the SSA website at www.SSA.gov...

--- Full Generation Check ---

Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/105 [00:00<00:00, 29746.84it/s, Materializing param=bert.embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/105 [00:00<00:00, 9039.45it/s, Materializing param=bert.embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/105 [00:00<00:00, 6781.41it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/105 [00:00<00:00, 5664.15it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 4381.24it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 3573.68it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 3694.61it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 3468.52it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/105 [00:00<00:00, 3505.77it/s, Materializing param=bert.embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/105 [00:00<00:00, 3340.48it/s, Materializing param=bert.embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 3022.20it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 2842.95it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 2798.33it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 2692.85it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/105 [00:00<00:00, 2614.70it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/105 [00:00<00:00, 2549.34it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2746.16it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2698.65it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2833.03it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2702.34it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2832.60it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2782.88it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2866.10it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2758.81it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2843.45it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2803.82it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2816.18it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]  
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2713.38it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2589.18it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2560.83it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2676.75it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]    
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2624.11it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2601.55it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2569.58it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2673.23it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2653.22it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2752.55it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2729.92it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2832.36it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2812.80it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2912.33it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2872.34it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2915.29it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2872.45it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2937.55it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2914.38it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2871.25it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2820.33it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2852.57it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2727.75it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2742.06it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2720.79it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2721.68it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2700.52it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2736.27it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2717.46it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2776.10it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2761.29it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2827.81it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2761.77it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2763.16it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2743.40it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2748.90it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]    
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2722.19it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2741.86it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2727.81it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2785.44it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2749.09it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2789.14it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2745.48it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2687.56it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]      
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2658.74it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2687.63it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2669.78it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2616.96it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2575.19it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2603.50it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2586.05it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2625.75it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]      
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2577.34it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2601.81it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2557.08it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2570.41it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]      
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2543.25it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2554.79it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2540.39it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2550.01it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2540.53it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2533.71it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2514.24it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2529.34it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]  
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2504.06it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2489.48it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2477.28it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2511.00it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]    
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2502.60it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2534.10it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2499.68it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2501.43it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2477.32it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2441.64it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2421.71it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2436.97it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]      
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2428.77it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2461.80it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2443.37it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2470.95it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2464.58it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2462.50it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2448.46it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2448.03it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]      
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2421.50it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2447.01it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2439.20it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2465.44it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]      
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2456.33it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2471.60it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2462.06it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2465.42it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2443.21it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2450.20it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2444.14it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2468.27it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]  
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2463.12it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2489.67it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2484.80it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2511.16it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]    
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2500.80it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2523.77it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2518.01it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2547.55it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2542.94it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2570.30it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2564.90it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2592.09it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]      
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2587.85it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2616.06it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2612.05it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2640.44it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2636.34it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2663.15it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2658.98it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2685.52it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]      
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2678.57it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2702.28it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2694.97it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2718.66it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]      
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2711.51it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2734.58it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2727.68it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2751.10it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2744.23it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2765.86it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2758.80it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2781.91it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]  
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2775.02it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2796.70it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2789.78it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2812.28it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]    
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2805.53it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2827.86it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2821.26it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2843.27it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2836.65it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2858.45it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2852.01it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2873.77it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]      
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2867.20it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2888.22it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2881.33it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2902.98it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2896.39it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2916.67it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2910.02it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 2931.22it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]      
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 2924.27it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 2943.93it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 2937.42it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 2957.79it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]      
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 2951.26it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 2970.38it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 2964.17it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 2982.25it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 2975.97it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 2996.58it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 2990.05it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3010.11it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]  
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3003.62it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3023.37it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3016.85it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3035.71it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]    
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3029.43it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3049.05it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3042.74it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3062.11it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3055.87it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3073.59it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3067.23it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3085.98it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]     
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3079.56it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3098.44it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3091.70it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3110.96it/s, Materializing param=bert.pooler.dense.bias]                  
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3104.82it/s, Materializing param=bert.pooler.dense.bias]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3123.22it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3117.02it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3136.20it/s, Materializing param=classifier.bias]         
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3130.08it/s, Materializing param=classifier.bias]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3149.69it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3143.71it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3128.37it/s, Materializing param=classifier.weight]
BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2
Key                          | Status     |  | 
-----------------------------+------------+--+-
bert.embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
No API keys found for tier ModelTier.FAST, falling back to local llama3.2

Response:
My date of birth is October 21, 1985.

Querying: 'What is 'The Book'?'

--- Direct Retrieval Check ---
Found 5 results.

Result 1 (Source: core_persona):
Content: rder in apparently random data.





12/5/06





This book is being put together in a chaotic fashion, and the structural elements of the book are in chaotic order, or relating to chaos theory.  The organization of book is like that.  





When I have told people I am writing a book they say, ôOh,...

Result 2 (Source: core_persona):
Content: rashers, Sideways, Billy Madison, Alice in Wonderland, Fight Club, THE LIFE OF DAVID GALE, Sliding Doors, Field Of Dreams, Kids, Numb, and OLD SCHOOL.

Favorite Books:

Angels and Demons, The Google Story, The Fabric of the Cosmos: Space, Time, and the Texture of Reality, and The Firm.

Favorite Quo...

Result 3 (Source: core_persona):
Content: s wearing and throwing him through the window of a 7-Eleven, buying weed out of a Jamaican store in Philly, getting in a fight with guys who were trying to sell me and my friends fake coke and having one of the guys pour a can of soda on my head, sitting in my apartment while my roommate got mugged ...

Result 4 (Source: core_persona):
Content: have achieved.  Every man should want more.





I want to reek havoc in the work world.  Like with whatever I end up doing I want to revolutionize the world, or at least an industry.  Like in ChappelleÆs show, the thug financial advisors.   





9/2/08





Ian Crossland wants to publish a book.  ...

Result 5 (Source: core_persona):
Content: H ANY OF THOSE THINGS LISTED ABOVE. All by age 23.  All of these experiencesàall they do is give me a really cool PERSPECTIVE. 





 (Put the above part in unison with the rest of the book, and the dichotomy is a perfect example of IVT.)





Ignorance is bliss?  To what extent is this an absolute?...

--- Full Generation Check ---

Response:
My book! It's a bit of a chaotic project, to be honest. I'm trying to put together a book that explores some philosophical and existential ideas, but it's not really about my life in the classical sense. I've been called out for saying it's "not really about my life," though - people seem to assume that's what the book is about! But really, it's more about looking beyond individual experiences and perspectives.

I'm drawn to certain themes and ideas, like chaos theory and the concept of a unified field. I've also been influenced by some interesting characters from movies and books, like Fight Club and Sliding Doors. And of course, there are my favorite quotes and thinkers - people like Angels and Demons author Dan Brown and physicist Brian Greene.

Overall, it's still a work in progress, but I'm hoping to produce something that's thought-provoking and maybe even insightful.
My book! It's a bit of a chaotic project, to be honest. I'm trying to put together a book that explores some philosophical and existential ideas, but it's not really about my life in the classical sense. I've been called out for saying it's "not really about my life," though - people seem to assume that's what the book is about! But really, it's more about looking beyond individual experiences and perspectives.

I'm drawn to certain themes and ideas, like chaos theory and the concept of a unified field. I've also been influenced by some interesting characters from movies and books, like Fight Club and Sliding Doors. And of course, there are my favorite quotes and thinkers - people like Angels and Demons author Dan Brown and physicist Brian Greene.

Overall, it's still a work in progress, but I'm hoping to produce something that's thought-provoking and maybe even insightful.
