Initializing RAG Engine...

Querying: 'What is my Date of Birth according to my health records?'

--- Direct Retrieval Check ---

Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/103 [00:00<00:00, 9845.78it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/103 [00:00<00:00, 2713.00it/s, Materializing param=embeddings.LayerNorm.bias]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2573.98it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/103 [00:00<00:00, 2005.88it/s, Materializing param=embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1842.30it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/103 [00:00<00:00, 1234.47it/s, Materializing param=embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 1527.70it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/103 [00:00<00:00, 1493.17it/s, Materializing param=embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/103 [00:00<00:00, 1673.04it/s, Materializing param=embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/103 [00:00<00:00, 1626.08it/s, Materializing param=embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 1772.87it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/103 [00:00<00:00, 1728.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 1704.41it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/103 [00:00<00:00, 1669.61it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/103 [00:00<00:00, 1814.15it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/103 [00:00<00:00, 1678.06it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1772.07it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/103 [00:00<00:00, 1745.44it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1782.61it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/103 [00:00<00:00, 1705.83it/s, Materializing param=encoder.layer.0.attention.self.key.bias]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1808.88it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#         | 11/103 [00:00<00:00, 1784.95it/s, Materializing param=encoder.layer.0.attention.self.key.weight]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1848.73it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#1        | 12/103 [00:00<00:00, 1825.86it/s, Materializing param=encoder.layer.0.attention.self.query.bias]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1936.22it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#2        | 13/103 [00:00<00:00, 1900.92it/s, Materializing param=encoder.layer.0.attention.self.query.weight]
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1987.96it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  
Loading weights:  14%|#3        | 14/103 [00:00<00:00, 1932.73it/s, Materializing param=encoder.layer.0.attention.self.value.bias]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1969.77it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#4        | 15/103 [00:00<00:00, 1949.57it/s, Materializing param=encoder.layer.0.attention.self.value.weight]
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1929.25it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    
Loading weights:  16%|#5        | 16/103 [00:00<00:00, 1911.99it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1936.27it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#6        | 17/103 [00:00<00:00, 1869.07it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1863.90it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/103 [00:00<00:00, 1845.81it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1892.92it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/103 [00:00<00:00, 1828.34it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1844.54it/s, Materializing param=encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/103 [00:00<00:00, 1829.50it/s, Materializing param=encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1894.98it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/103 [00:00<00:00, 1881.46it/s, Materializing param=encoder.layer.0.output.dense.weight]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1904.93it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##1       | 22/103 [00:00<00:00, 1891.53it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1927.34it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##2       | 23/103 [00:00<00:00, 1916.73it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1943.61it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##3       | 24/103 [00:00<00:00, 1930.63it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1988.27it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##4       | 25/103 [00:00<00:00, 1960.76it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2013.77it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##5       | 26/103 [00:00<00:00, 2003.97it/s, Materializing param=encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 2022.04it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##6       | 27/103 [00:00<00:00, 1998.77it/s, Materializing param=encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2048.25it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##7       | 28/103 [00:00<00:00, 2039.57it/s, Materializing param=encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2055.65it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##8       | 29/103 [00:00<00:00, 2045.62it/s, Materializing param=encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2077.66it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##9       | 30/103 [00:00<00:00, 2064.67it/s, Materializing param=encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2021.57it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 31/103 [00:00<00:00, 2002.83it/s, Materializing param=encoder.layer.1.attention.self.value.weight]
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2031.42it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    
Loading weights:  31%|###1      | 32/103 [00:00<00:00, 2017.49it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2016.05it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 33/103 [00:00<00:00, 2006.47it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2029.09it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  33%|###3      | 34/103 [00:00<00:00, 2012.85it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2023.97it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###3      | 35/103 [00:00<00:00, 2013.28it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 2015.68it/s, Materializing param=encoder.layer.1.output.dense.bias]      
Loading weights:  35%|###4      | 36/103 [00:00<00:00, 1992.20it/s, Materializing param=encoder.layer.1.output.dense.bias]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1895.05it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  36%|###5      | 37/103 [00:00<00:00, 1865.70it/s, Materializing param=encoder.layer.1.output.dense.weight]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1872.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###6      | 38/103 [00:00<00:00, 1864.09it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1897.92it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###7      | 39/103 [00:00<00:00, 1885.82it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1897.90it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      
Loading weights:  39%|###8      | 40/103 [00:00<00:00, 1885.53it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1896.26it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|###9      | 41/103 [00:00<00:00, 1860.02it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]
Loading weights:  41%|####      | 42/103 [00:00<00:00, 1882.94it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      
Loading weights:  41%|####      | 42/103 [00:00<00:00, 1866.88it/s, Materializing param=encoder.layer.2.attention.self.key.bias]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1879.99it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 43/103 [00:00<00:00, 1871.62it/s, Materializing param=encoder.layer.2.attention.self.key.weight]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1886.99it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 44/103 [00:00<00:00, 1878.73it/s, Materializing param=encoder.layer.2.attention.self.query.bias]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1886.68it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 45/103 [00:00<00:00, 1870.06it/s, Materializing param=encoder.layer.2.attention.self.query.weight]
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1871.04it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  
Loading weights:  45%|####4     | 46/103 [00:00<00:00, 1856.46it/s, Materializing param=encoder.layer.2.attention.self.value.bias]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1882.31it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 47/103 [00:00<00:00, 1877.34it/s, Materializing param=encoder.layer.2.attention.self.value.weight]
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1908.36it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    
Loading weights:  47%|####6     | 48/103 [00:00<00:00, 1903.74it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1934.35it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 49/103 [00:00<00:00, 1929.83it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1955.84it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  49%|####8     | 50/103 [00:00<00:00, 1950.51it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1978.68it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 51/103 [00:00<00:00, 1974.63it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2005.68it/s, Materializing param=encoder.layer.2.output.dense.bias]      
Loading weights:  50%|#####     | 52/103 [00:00<00:00, 2000.24it/s, Materializing param=encoder.layer.2.output.dense.bias]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2029.86it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 53/103 [00:00<00:00, 2025.66it/s, Materializing param=encoder.layer.2.output.dense.weight]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2055.75it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 54/103 [00:00<00:00, 2051.34it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2077.98it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 55/103 [00:00<00:00, 2071.91it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2099.87it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      
Loading weights:  54%|#####4    | 56/103 [00:00<00:00, 2091.79it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2117.27it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 57/103 [00:00<00:00, 2111.77it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2138.24it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      
Loading weights:  56%|#####6    | 58/103 [00:00<00:00, 2134.08it/s, Materializing param=encoder.layer.3.attention.self.key.bias]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2162.24it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 59/103 [00:00<00:00, 2157.77it/s, Materializing param=encoder.layer.3.attention.self.key.weight]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2183.32it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 60/103 [00:00<00:00, 2178.48it/s, Materializing param=encoder.layer.3.attention.self.query.bias]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2206.27it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 61/103 [00:00<00:00, 2202.00it/s, Materializing param=encoder.layer.3.attention.self.query.weight]
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2229.60it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  
Loading weights:  60%|######    | 62/103 [00:00<00:00, 2224.71it/s, Materializing param=encoder.layer.3.attention.self.value.bias]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2251.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######1   | 63/103 [00:00<00:00, 2246.30it/s, Materializing param=encoder.layer.3.attention.self.value.weight]
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2273.05it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    
Loading weights:  62%|######2   | 64/103 [00:00<00:00, 2268.17it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2283.43it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######3   | 65/103 [00:00<00:00, 2276.54it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2300.73it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  64%|######4   | 66/103 [00:00<00:00, 2296.08it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2319.09it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######5   | 67/103 [00:00<00:00, 2312.98it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2333.91it/s, Materializing param=encoder.layer.3.output.dense.bias]      
Loading weights:  66%|######6   | 68/103 [00:00<00:00, 2327.01it/s, Materializing param=encoder.layer.3.output.dense.bias]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2349.10it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 69/103 [00:00<00:00, 2344.14it/s, Materializing param=encoder.layer.3.output.dense.weight]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2369.38it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 70/103 [00:00<00:00, 2364.45it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2386.28it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 71/103 [00:00<00:00, 2380.63it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2403.75it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      
Loading weights:  70%|######9   | 72/103 [00:00<00:00, 2399.11it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2421.58it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  71%|#######   | 73/103 [00:00<00:00, 2414.36it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2436.04it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      
Loading weights:  72%|#######1  | 74/103 [00:00<00:00, 2431.79it/s, Materializing param=encoder.layer.4.attention.self.key.bias]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2452.08it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  73%|#######2  | 75/103 [00:00<00:00, 2447.47it/s, Materializing param=encoder.layer.4.attention.self.key.weight]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2471.58it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  74%|#######3  | 76/103 [00:00<00:00, 2467.12it/s, Materializing param=encoder.layer.4.attention.self.query.bias]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2491.33it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  75%|#######4  | 77/103 [00:00<00:00, 2487.00it/s, Materializing param=encoder.layer.4.attention.self.query.weight]
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2511.29it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  
Loading weights:  76%|#######5  | 78/103 [00:00<00:00, 2506.81it/s, Materializing param=encoder.layer.4.attention.self.value.bias]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2529.97it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  77%|#######6  | 79/103 [00:00<00:00, 2525.32it/s, Materializing param=encoder.layer.4.attention.self.value.weight]
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2548.22it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    
Loading weights:  78%|#######7  | 80/103 [00:00<00:00, 2543.12it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 2565.81it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  79%|#######8  | 81/103 [00:00<00:00, 2561.88it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 2586.06it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  80%|#######9  | 82/103 [00:00<00:00, 2582.66it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 2607.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  81%|########  | 83/103 [00:00<00:00, 2603.97it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 2628.48it/s, Materializing param=encoder.layer.4.output.dense.bias]      
Loading weights:  82%|########1 | 84/103 [00:00<00:00, 2622.10it/s, Materializing param=encoder.layer.4.output.dense.bias]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 2646.25it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########2 | 85/103 [00:00<00:00, 2642.89it/s, Materializing param=encoder.layer.4.output.dense.weight]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 2665.71it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########3 | 86/103 [00:00<00:00, 2661.85it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 2684.78it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########4 | 87/103 [00:00<00:00, 2681.23it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 2703.19it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      
Loading weights:  85%|########5 | 88/103 [00:00<00:00, 2699.45it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 2721.31it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########6 | 89/103 [00:00<00:00, 2717.98it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 2740.98it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      
Loading weights:  87%|########7 | 90/103 [00:00<00:00, 2737.32it/s, Materializing param=encoder.layer.5.attention.self.key.bias]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 2758.93it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########8 | 91/103 [00:00<00:00, 2755.29it/s, Materializing param=encoder.layer.5.attention.self.key.weight]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 2774.03it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########9 | 92/103 [00:00<00:00, 2768.32it/s, Materializing param=encoder.layer.5.attention.self.query.bias]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 2788.97it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|######### | 93/103 [00:00<00:00, 2776.93it/s, Materializing param=encoder.layer.5.attention.self.query.weight]
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 2794.28it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  
Loading weights:  91%|#########1| 94/103 [00:00<00:00, 2789.59it/s, Materializing param=encoder.layer.5.attention.self.value.bias]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 2809.71it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  92%|#########2| 95/103 [00:00<00:00, 2805.16it/s, Materializing param=encoder.layer.5.attention.self.value.weight]
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 2825.56it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    
Loading weights:  93%|#########3| 96/103 [00:00<00:00, 2821.32it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 2841.79it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  94%|#########4| 97/103 [00:00<00:00, 2836.54it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 2854.54it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  95%|#########5| 98/103 [00:00<00:00, 2849.00it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 2863.10it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  96%|#########6| 99/103 [00:00<00:00, 2857.08it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 2874.78it/s, Materializing param=encoder.layer.5.output.dense.bias]     
Loading weights:  97%|#########7| 100/103 [00:00<00:00, 2870.59it/s, Materializing param=encoder.layer.5.output.dense.bias]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 2890.77it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  98%|#########8| 101/103 [00:00<00:00, 2886.73it/s, Materializing param=encoder.layer.5.output.dense.weight]
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 2907.84it/s, Materializing param=pooler.dense.bias]                  
Loading weights:  99%|#########9| 102/103 [00:00<00:00, 2903.79it/s, Materializing param=pooler.dense.bias]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 2925.10it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 2921.00it/s, Materializing param=pooler.dense.weight]
Loading weights: 100%|##########| 103/103 [00:00<00:00, 2909.49it/s, Materializing param=pooler.dense.weight]
BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2
Key                     | Status     |  | 
------------------------+------------+--+-
embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
Found 5 results.

Result 1 (Source: health_folder):
Content: itoring of kidney function due to hereditary risk.
This document summarizes your health trends based on medical records from 2021û2025 and your
recent lifestyle updates....

Result 2 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 3 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 4 (Source: finance_folder):
Content: ountö line of your tax return theamount shown in this box plus the amount in box 6, if any.     If this is a total distribution from a qualified plan and you were bornbefore January 2, 1936 (or you're the beneficiary of someone bornbefore January 2, 1936), you may be eligible for the 10-year tax opt...

Result 5 (Source: finance_folder):
Content: ns made so you may file them
with your tax return. If your name and SSN are correct but
arenÆt the same as shown on your social security card, you
should ask for a new card that displays your correct name
at any SSA office or by calling 800-772-1213. You may also
visit the SSA website at www.SSA.gov...

--- Full Generation Check ---
System Prompt Length: 1560

Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]
Loading weights:   1%|          | 1/105 [00:00<00:00, 46603.38it/s, Materializing param=bert.embeddings.LayerNorm.bias]
Loading weights:   1%|          | 1/105 [00:00<00:00, 5210.32it/s, Materializing param=bert.embeddings.LayerNorm.bias] 
Loading weights:   2%|1         | 2/105 [00:00<00:00, 3771.86it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   2%|1         | 2/105 [00:00<00:00, 3071.63it/s, Materializing param=bert.embeddings.LayerNorm.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 3342.96it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   3%|2         | 3/105 [00:00<00:00, 2331.46it/s, Materializing param=bert.embeddings.position_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 2217.16it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   4%|3         | 4/105 [00:00<00:00, 2138.59it/s, Materializing param=bert.embeddings.token_type_embeddings.weight]
Loading weights:   5%|4         | 5/105 [00:00<00:00, 2483.01it/s, Materializing param=bert.embeddings.word_embeddings.weight]      
Loading weights:   5%|4         | 5/105 [00:00<00:00, 2418.02it/s, Materializing param=bert.embeddings.word_embeddings.weight]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 2769.13it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   6%|5         | 6/105 [00:00<00:00, 2714.17it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.bias]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 3012.53it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   7%|6         | 7/105 [00:00<00:00, 2809.85it/s, Materializing param=bert.encoder.layer.0.attention.output.LayerNorm.weight]
Loading weights:   8%|7         | 8/105 [00:00<00:00, 3008.29it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]      
Loading weights:   8%|7         | 8/105 [00:00<00:00, 2684.78it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.bias]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2847.24it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:   9%|8         | 9/105 [00:00<00:00, 2710.28it/s, Materializing param=bert.encoder.layer.0.attention.output.dense.weight]
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2840.13it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]     
Loading weights:  10%|9         | 10/105 [00:00<00:00, 2675.96it/s, Materializing param=bert.encoder.layer.0.attention.self.key.bias]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2735.20it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  10%|#         | 11/105 [00:00<00:00, 2693.21it/s, Materializing param=bert.encoder.layer.0.attention.self.key.weight]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2725.49it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  11%|#1        | 12/105 [00:00<00:00, 2672.81it/s, Materializing param=bert.encoder.layer.0.attention.self.query.bias]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2804.40it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  12%|#2        | 13/105 [00:00<00:00, 2755.09it/s, Materializing param=bert.encoder.layer.0.attention.self.query.weight]
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2802.61it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]  
Loading weights:  13%|#3        | 14/105 [00:00<00:00, 2691.98it/s, Materializing param=bert.encoder.layer.0.attention.self.value.bias]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2781.98it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  14%|#4        | 15/105 [00:00<00:00, 2744.60it/s, Materializing param=bert.encoder.layer.0.attention.self.value.weight]
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2795.04it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]    
Loading weights:  15%|#5        | 16/105 [00:00<00:00, 2706.77it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.bias]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2754.51it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  16%|#6        | 17/105 [00:00<00:00, 2725.45it/s, Materializing param=bert.encoder.layer.0.intermediate.dense.weight]
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2687.03it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]    
Loading weights:  17%|#7        | 18/105 [00:00<00:00, 2614.00it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.bias]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2644.93it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  18%|#8        | 19/105 [00:00<00:00, 2612.16it/s, Materializing param=bert.encoder.layer.0.output.LayerNorm.weight]
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2658.83it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]      
Loading weights:  19%|#9        | 20/105 [00:00<00:00, 2624.89it/s, Materializing param=bert.encoder.layer.0.output.dense.bias]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2578.84it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  20%|##        | 21/105 [00:00<00:00, 2549.73it/s, Materializing param=bert.encoder.layer.0.output.dense.weight]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2607.88it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  21%|##        | 22/105 [00:00<00:00, 2520.62it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.bias]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2586.72it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  22%|##1       | 23/105 [00:00<00:00, 2533.79it/s, Materializing param=bert.encoder.layer.1.attention.output.LayerNorm.weight]
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2574.18it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]      
Loading weights:  23%|##2       | 24/105 [00:00<00:00, 2552.44it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.bias]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2565.89it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  24%|##3       | 25/105 [00:00<00:00, 2544.72it/s, Materializing param=bert.encoder.layer.1.attention.output.dense.weight]
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2595.61it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]      
Loading weights:  25%|##4       | 26/105 [00:00<00:00, 2546.63it/s, Materializing param=bert.encoder.layer.1.attention.self.key.bias]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2609.36it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  26%|##5       | 27/105 [00:00<00:00, 2594.83it/s, Materializing param=bert.encoder.layer.1.attention.self.key.weight]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2575.11it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  27%|##6       | 28/105 [00:00<00:00, 2552.56it/s, Materializing param=bert.encoder.layer.1.attention.self.query.bias]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2608.96it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  28%|##7       | 29/105 [00:00<00:00, 2587.09it/s, Materializing param=bert.encoder.layer.1.attention.self.query.weight]
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2637.93it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]  
Loading weights:  29%|##8       | 30/105 [00:00<00:00, 2565.06it/s, Materializing param=bert.encoder.layer.1.attention.self.value.bias]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2554.64it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|##9       | 31/105 [00:00<00:00, 2519.74it/s, Materializing param=bert.encoder.layer.1.attention.self.value.weight]
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2566.84it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]    
Loading weights:  30%|###       | 32/105 [00:00<00:00, 2540.70it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.bias]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2585.06it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  31%|###1      | 33/105 [00:00<00:00, 2565.80it/s, Materializing param=bert.encoder.layer.1.intermediate.dense.weight]
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2575.75it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]    
Loading weights:  32%|###2      | 34/105 [00:00<00:00, 2535.76it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.bias]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2492.54it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  33%|###3      | 35/105 [00:00<00:00, 2472.02it/s, Materializing param=bert.encoder.layer.1.output.LayerNorm.weight]
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2493.68it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]      
Loading weights:  34%|###4      | 36/105 [00:00<00:00, 2481.06it/s, Materializing param=bert.encoder.layer.1.output.dense.bias]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2529.74it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  35%|###5      | 37/105 [00:00<00:00, 2520.86it/s, Materializing param=bert.encoder.layer.1.output.dense.weight]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2525.85it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  36%|###6      | 38/105 [00:00<00:00, 2484.54it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.bias]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2516.50it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  37%|###7      | 39/105 [00:00<00:00, 2505.02it/s, Materializing param=bert.encoder.layer.2.attention.output.LayerNorm.weight]
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2518.12it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]      
Loading weights:  38%|###8      | 40/105 [00:00<00:00, 2498.69it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.bias]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2520.32it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  39%|###9      | 41/105 [00:00<00:00, 2511.38it/s, Materializing param=bert.encoder.layer.2.attention.output.dense.weight]
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2520.00it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]      
Loading weights:  40%|####      | 42/105 [00:00<00:00, 2509.20it/s, Materializing param=bert.encoder.layer.2.attention.self.key.bias]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2533.72it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  41%|####      | 43/105 [00:00<00:00, 2489.06it/s, Materializing param=bert.encoder.layer.2.attention.self.key.weight]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2506.17it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  42%|####1     | 44/105 [00:00<00:00, 2496.64it/s, Materializing param=bert.encoder.layer.2.attention.self.query.bias]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2533.54it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  43%|####2     | 45/105 [00:00<00:00, 2524.02it/s, Materializing param=bert.encoder.layer.2.attention.self.query.weight]
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2507.45it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]  
Loading weights:  44%|####3     | 46/105 [00:00<00:00, 2491.29it/s, Materializing param=bert.encoder.layer.2.attention.self.value.bias]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2523.10it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  45%|####4     | 47/105 [00:00<00:00, 2515.15it/s, Materializing param=bert.encoder.layer.2.attention.self.value.weight]
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2544.03it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]    
Loading weights:  46%|####5     | 48/105 [00:00<00:00, 2498.07it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.bias]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2529.11it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  47%|####6     | 49/105 [00:00<00:00, 2487.06it/s, Materializing param=bert.encoder.layer.2.intermediate.dense.weight]
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2518.28it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]    
Loading weights:  48%|####7     | 50/105 [00:00<00:00, 2510.03it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.bias]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2539.38it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  49%|####8     | 51/105 [00:00<00:00, 2520.29it/s, Materializing param=bert.encoder.layer.2.output.LayerNorm.weight]
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2523.24it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]      
Loading weights:  50%|####9     | 52/105 [00:00<00:00, 2511.94it/s, Materializing param=bert.encoder.layer.2.output.dense.bias]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2541.45it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  50%|#####     | 53/105 [00:00<00:00, 2532.76it/s, Materializing param=bert.encoder.layer.2.output.dense.weight]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2551.42it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  51%|#####1    | 54/105 [00:00<00:00, 2529.65it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.bias]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2537.64it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  52%|#####2    | 55/105 [00:00<00:00, 2528.57it/s, Materializing param=bert.encoder.layer.3.attention.output.LayerNorm.weight]
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2518.91it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]      
Loading weights:  53%|#####3    | 56/105 [00:00<00:00, 2505.48it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.bias]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2465.91it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  54%|#####4    | 57/105 [00:00<00:00, 2445.81it/s, Materializing param=bert.encoder.layer.3.attention.output.dense.weight]
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2443.47it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]      
Loading weights:  55%|#####5    | 58/105 [00:00<00:00, 2436.72it/s, Materializing param=bert.encoder.layer.3.attention.self.key.bias]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2438.86it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  56%|#####6    | 59/105 [00:00<00:00, 2421.01it/s, Materializing param=bert.encoder.layer.3.attention.self.key.weight]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2445.25it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  57%|#####7    | 60/105 [00:00<00:00, 2437.67it/s, Materializing param=bert.encoder.layer.3.attention.self.query.bias]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2466.29it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  58%|#####8    | 61/105 [00:00<00:00, 2456.98it/s, Materializing param=bert.encoder.layer.3.attention.self.query.weight]
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2477.91it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]  
Loading weights:  59%|#####9    | 62/105 [00:00<00:00, 2469.77it/s, Materializing param=bert.encoder.layer.3.attention.self.value.bias]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2493.12it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  60%|######    | 63/105 [00:00<00:00, 2486.30it/s, Materializing param=bert.encoder.layer.3.attention.self.value.weight]
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2511.44it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]    
Loading weights:  61%|######    | 64/105 [00:00<00:00, 2504.60it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.bias]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2529.46it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  62%|######1   | 65/105 [00:00<00:00, 2521.71it/s, Materializing param=bert.encoder.layer.3.intermediate.dense.weight]
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2550.10it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]    
Loading weights:  63%|######2   | 66/105 [00:00<00:00, 2544.74it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.bias]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2571.57it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  64%|######3   | 67/105 [00:00<00:00, 2564.13it/s, Materializing param=bert.encoder.layer.3.output.LayerNorm.weight]
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2588.40it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]      
Loading weights:  65%|######4   | 68/105 [00:00<00:00, 2582.58it/s, Materializing param=bert.encoder.layer.3.output.dense.bias]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2606.24it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  66%|######5   | 69/105 [00:00<00:00, 2598.37it/s, Materializing param=bert.encoder.layer.3.output.dense.weight]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2620.04it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  67%|######6   | 70/105 [00:00<00:00, 2612.55it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.bias]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2637.16it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  68%|######7   | 71/105 [00:00<00:00, 2631.59it/s, Materializing param=bert.encoder.layer.4.attention.output.LayerNorm.weight]
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2658.31it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]      
Loading weights:  69%|######8   | 72/105 [00:00<00:00, 2651.99it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.bias]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2673.93it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|######9   | 73/105 [00:00<00:00, 2667.41it/s, Materializing param=bert.encoder.layer.4.attention.output.dense.weight]
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2694.66it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]      
Loading weights:  70%|#######   | 74/105 [00:00<00:00, 2689.82it/s, Materializing param=bert.encoder.layer.4.attention.self.key.bias]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2717.60it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  71%|#######1  | 75/105 [00:00<00:00, 2713.17it/s, Materializing param=bert.encoder.layer.4.attention.self.key.weight]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2740.62it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  72%|#######2  | 76/105 [00:00<00:00, 2735.40it/s, Materializing param=bert.encoder.layer.4.attention.self.query.bias]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2762.90it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  73%|#######3  | 77/105 [00:00<00:00, 2758.49it/s, Materializing param=bert.encoder.layer.4.attention.self.query.weight]
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2786.44it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]  
Loading weights:  74%|#######4  | 78/105 [00:00<00:00, 2782.22it/s, Materializing param=bert.encoder.layer.4.attention.self.value.bias]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2810.22it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  75%|#######5  | 79/105 [00:00<00:00, 2806.03it/s, Materializing param=bert.encoder.layer.4.attention.self.value.weight]
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2834.04it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]    
Loading weights:  76%|#######6  | 80/105 [00:00<00:00, 2829.95it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.bias]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2857.71it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  77%|#######7  | 81/105 [00:00<00:00, 2852.38it/s, Materializing param=bert.encoder.layer.4.intermediate.dense.weight]
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2875.53it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]    
Loading weights:  78%|#######8  | 82/105 [00:00<00:00, 2870.25it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.bias]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2896.38it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  79%|#######9  | 83/105 [00:00<00:00, 2891.73it/s, Materializing param=bert.encoder.layer.4.output.LayerNorm.weight]
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2918.45it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]      
Loading weights:  80%|########  | 84/105 [00:00<00:00, 2914.08it/s, Materializing param=bert.encoder.layer.4.output.dense.bias]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2940.80it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  81%|########  | 85/105 [00:00<00:00, 2936.49it/s, Materializing param=bert.encoder.layer.4.output.dense.weight]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2963.54it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  82%|########1 | 86/105 [00:00<00:00, 2959.16it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.bias]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2983.34it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  83%|########2 | 87/105 [00:00<00:00, 2978.69it/s, Materializing param=bert.encoder.layer.5.attention.output.LayerNorm.weight]
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 3004.93it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]      
Loading weights:  84%|########3 | 88/105 [00:00<00:00, 3000.53it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.bias]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 3026.71it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  85%|########4 | 89/105 [00:00<00:00, 3022.32it/s, Materializing param=bert.encoder.layer.5.attention.output.dense.weight]
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 3048.38it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]      
Loading weights:  86%|########5 | 90/105 [00:00<00:00, 3044.06it/s, Materializing param=bert.encoder.layer.5.attention.self.key.bias]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 3070.13it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  87%|########6 | 91/105 [00:00<00:00, 3065.84it/s, Materializing param=bert.encoder.layer.5.attention.self.key.weight]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 3090.82it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  88%|########7 | 92/105 [00:00<00:00, 3086.32it/s, Materializing param=bert.encoder.layer.5.attention.self.query.bias]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 3112.15it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  89%|########8 | 93/105 [00:00<00:00, 3107.61it/s, Materializing param=bert.encoder.layer.5.attention.self.query.weight]
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3132.94it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]  
Loading weights:  90%|########9 | 94/105 [00:00<00:00, 3128.04it/s, Materializing param=bert.encoder.layer.5.attention.self.value.bias]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3152.31it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  90%|######### | 95/105 [00:00<00:00, 3147.86it/s, Materializing param=bert.encoder.layer.5.attention.self.value.weight]
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3173.20it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]    
Loading weights:  91%|#########1| 96/105 [00:00<00:00, 3168.73it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.bias]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3193.42it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  92%|#########2| 97/105 [00:00<00:00, 3188.91it/s, Materializing param=bert.encoder.layer.5.intermediate.dense.weight]
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3214.23it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]    
Loading weights:  93%|#########3| 98/105 [00:00<00:00, 3209.51it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.bias]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3231.59it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  94%|#########4| 99/105 [00:00<00:00, 3224.81it/s, Materializing param=bert.encoder.layer.5.output.LayerNorm.weight]
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3247.47it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]     
Loading weights:  95%|#########5| 100/105 [00:00<00:00, 3242.48it/s, Materializing param=bert.encoder.layer.5.output.dense.bias]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3266.01it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  96%|#########6| 101/105 [00:00<00:00, 3261.21it/s, Materializing param=bert.encoder.layer.5.output.dense.weight]
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3285.38it/s, Materializing param=bert.pooler.dense.bias]                  
Loading weights:  97%|#########7| 102/105 [00:00<00:00, 3281.10it/s, Materializing param=bert.pooler.dense.bias]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3305.76it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  98%|#########8| 103/105 [00:00<00:00, 3301.39it/s, Materializing param=bert.pooler.dense.weight]
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3326.12it/s, Materializing param=classifier.bias]         
Loading weights:  99%|#########9| 104/105 [00:00<00:00, 3321.77it/s, Materializing param=classifier.bias]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3346.49it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3342.15it/s, Materializing param=classifier.weight]
Loading weights: 100%|##########| 105/105 [00:00<00:00, 3332.04it/s, Materializing param=classifier.weight]
BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2
Key                          | Status     |  | 
-----------------------------+------------+--+-
bert.embeddings.position_ids | UNEXPECTED |  | 

Notes:
- UNEXPECTED	:can be ignored when loading from different task/architecture; not ok if you expect identical arch.
Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
No API keys found for tier ModelTier.FAST, falling back to local llama3.2
No API keys found for tier ModelTier.FAST, falling back to local llama3.2

Response:
My date of birth, as recorded in my health files, is October 21, 1985. That's a pretty clear one!

Querying: 'What is 'The Book'?'

--- Direct Retrieval Check ---
Found 5 results.

Result 1 (Source: core_persona):
Content: rder in apparently random data.





12/5/06





This book is being put together in a chaotic fashion, and the structural elements of the book are in chaotic order, or relating to chaos theory.  The organization of book is like that.  





When I have told people I am writing a book they say, ôOh,...

Result 2 (Source: core_persona):
Content: rashers, Sideways, Billy Madison, Alice in Wonderland, Fight Club, THE LIFE OF DAVID GALE, Sliding Doors, Field Of Dreams, Kids, Numb, and OLD SCHOOL.

Favorite Books:

Angels and Demons, The Google Story, The Fabric of the Cosmos: Space, Time, and the Texture of Reality, and The Firm.

Favorite Quo...

Result 3 (Source: core_persona):
Content: s wearing and throwing him through the window of a 7-Eleven, buying weed out of a Jamaican store in Philly, getting in a fight with guys who were trying to sell me and my friends fake coke and having one of the guys pour a can of soda on my head, sitting in my apartment while my roommate got mugged ...

Result 4 (Source: core_persona):
Content: have achieved.  Every man should want more.





I want to reek havoc in the work world.  Like with whatever I end up doing I want to revolutionize the world, or at least an industry.  Like in ChappelleÆs show, the thug financial advisors.   





9/2/08





Ian Crossland wants to publish a book.  ...

Result 5 (Source: core_persona):
Content: H ANY OF THOSE THINGS LISTED ABOVE. All by age 23.  All of these experiencesàall they do is give me a really cool PERSPECTIVE. 





 (Put the above part in unison with the rest of the book, and the dichotomy is a perfect example of IVT.)





Ignorance is bliss?  To what extent is this an absolute?...

--- Full Generation Check ---
System Prompt Length: 1560

Response:
"The Book"! That's the title I've been working on for years, and it's still taking shape. It's not really about my life, but more about looking beyond it û exploring the connections between chaos theory, philosophy, and... well, just about everything else that interests me.

I've got a bunch of favorite books, quotes, and movies that have shaped my perspective on the world. And I'm trying to weave all those threads together into something bigger than myself. It's still a work in progress, but I hope it'll be a thought-provoking read for anyone who's curious about the nature of reality and human experience.
